{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping data now after Excel cleanong, we imputted as much data as possible , now im going to drop data with values nan and \"No Value\" from each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xls = pd.ExcelFile(\"Excel Clean.xlsx\")\n",
    "#print(xls.sheet_names)  # Lists all sheet names\n",
    "\n",
    "df = pd.read_excel(\"Excel Clean.xlsx\", sheet_name=\"Cleaned_Cafe_Data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Items</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Grand total</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Days_of_week</th>\n",
       "      <th>Location_was_unavailable</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1000555</td>\n",
       "      <td>Tea</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>1900-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cake</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_1001832</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>1900-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_1002457</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>1900-01-06</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_1003246</td>\n",
       "      <td>Juice</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>1900-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juice</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_1004184</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>1900-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salad</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID     Items Quantity Price Per Unit Grand total  \\\n",
       "0    TXN_1000555       Tea        1            1.5         1.5   \n",
       "1    TXN_1001832     Salad        2              5          10   \n",
       "2    TXN_1002457    Cookie        5              1           5   \n",
       "3    TXN_1003246     Juice        2              3           6   \n",
       "4    TXN_1004184  Smoothie        1              4           4   \n",
       "\n",
       "   Payment Method  Location Transaction Date Days_of_week  \\\n",
       "0     Credit Card  In-store       2023-10-19   1900-01-05   \n",
       "1            Cash  Takeaway       2023-10-19   1900-01-05   \n",
       "2  Digital Wallet  Takeaway       2023-09-29   1900-01-06   \n",
       "3             NaN       NaN       2023-02-15   1900-01-04   \n",
       "4     Credit Card  In-store       2023-05-18   1900-01-05   \n",
       "\n",
       "   Location_was_unavailable  Unnamed: 10  Unnamed: 11 Product  Price  \n",
       "0                     False          NaN          NaN    Cake    3.0  \n",
       "1                     False          NaN          NaN  Coffee    2.0  \n",
       "2                     False          NaN          NaN  Cookie    1.0  \n",
       "3                      True          NaN          NaN   Juice    3.0  \n",
       "4                     False          NaN          NaN   Salad    5.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID                  0\n",
       "Items                         512\n",
       "Quantity                       18\n",
       "Price Per Unit                 38\n",
       "Grand total                    20\n",
       "Payment Method               3178\n",
       "Location                     3961\n",
       "Transaction Date                0\n",
       "Days_of_week                    0\n",
       "Location_was_unavailable        0\n",
       "Unnamed: 10                 10000\n",
       "Unnamed: 11                 10000\n",
       "Product                      9992\n",
       "Price                        9992\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum() + (df == \"No Value\").sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop na and no value cells from items,quantity, price per unit and grand total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clean = ['Items', 'Quantity', 'Price Per Unit', 'Grand total']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this row contains 'no value' (even if that 'no value' was typed differently), but don’t mess with the actual data types while doing it.\n",
    "df[cols_to_clean]\n",
    "→ Select just the important columns you're cleaning (like Items, Quantity, etc.).\n",
    "\n",
    ".apply(..., axis=1)\n",
    "→ Go through each row of those columns.\n",
    "\n",
    "lambda row: ...\n",
    "→ Temporarily convert each cell in the row to a string, clean it (strip spaces, lowercase), and check if it equals \"no value\".\n",
    "\n",
    ".any(axis=1)\n",
    "→ Now, for each row, ask: \"Was any cell equal to 'no value'?\"\n",
    "\n",
    "If yes → this row is bad, we want to remove it.\n",
    "\n",
    "If no → this row is good, we want to keep it.\n",
    "\n",
    "~ (tilde)\n",
    "→ Flip the logic! Now we're keeping rows that do NOT contain \"no value\".\n",
    "\n",
    "df[...]\n",
    "→ We're using that result to filter the DataFrame and assign it back to df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop rows with \"No Value\" (case-insensitive string match)\n",
    "#df = df[~df[cols_to_clean].apply( # ~ Keep only the rows that do NOT have \"no value\" in them.  .apply: This applies a function to each row (axis=1 = row-wise).\n",
    "#    lambda row: row.astype(str).str.strip().str.lower().eq(\"no value\"), axis=1 # This defines what to do for each row of those selected columns.\n",
    "#).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop NaNs in those columns\n",
    "#df.dropna(subset=cols_to_clean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Drop rows with 0 in Quantity, Price Per Unit, or Grand total\n",
    "#df = df[~((df['Quantity'] == 0) | (df['Price Per Unit'] == 0) | (df['Grand total'] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Reset index\n",
    "# df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER APPROACH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cols_to_check = [\"Items\", \"Quantity\", \"Price Per Unit\", \"Grand total\"]\\n\\n# Check how many \\'bad\\' values are in each row for those 4 columns\\nbad_counts = df[cols_to_check].apply(\\n    lambda row: sum((pd.isna(row)) | (row.astype(str).str.strip().str.lower() == \"no value\")),\\n    axis=1\\n)\\n\\n# Count how many rows had 3 or more bad values\\nprint(\"Rows with 2 or more bad values in important columns:\", (bad_counts >= 2).sum())\\n\\ndf = df[bad_counts < 2]  # keep rows with 0, 1, or bad values\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cols_to_check = [\"Items\", \"Quantity\", \"Price Per Unit\", \"Grand total\"]\n",
    "\n",
    "# Check how many 'bad' values are in each row for those 4 columns\n",
    "bad_counts = df[cols_to_check].apply(\n",
    "    lambda row: sum((pd.isna(row)) | (row.astype(str).str.strip().str.lower() == \"no value\")),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count how many rows had 3 or more bad values\n",
    "print(\"Rows with 2 or more bad values in important columns:\", (bad_counts >= 2).sum())\n",
    "\n",
    "df = df[bad_counts < 2]  # keep rows with 0, 1, or bad values\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea: In the same row, if columns: Payment Method and Location Column are any of the following (No value, 0, nan), AND if in the cols_to_check, in one of those columns in the SAME row still, if any one of them are also (no value, 0 , nan) then drop that entire row! \n",
    "\n",
    "it drops rows if:\n",
    "\n",
    "Payment Method or Location are blank, and\n",
    "\n",
    "There are 2 or more “bad” values in the important columns (Items, Quantity, PPU, Grand Total).\n",
    "\n",
    "Item | Quantity | PPU | GT |     Location       | PM\n",
    "0       NA         2      2       No value       No value -->drop (if >= 2 values are missing)\n",
    "1      0          2       2    No value          No value -->dont drop \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = [\"Items\", \"Quantity\", \"Price Per Unit\", \"Grand total\"]\n",
    "\n",
    "def is_blank(val):\n",
    "    return pd.isna(val) or str(val).strip() == \"\"\n",
    "\n",
    "df = df[~df.apply(\n",
    "    lambda row: (\n",
    "        # Check if either Payment Method or Location is blank\n",
    "        is_blank(row[\"Payment Method\"]) or is_blank(row[\"Location\"])\n",
    "    ) and (\n",
    "        # Check if 2 or more of the important columns are bad\n",
    "        sum(is_blank(row[col]) or str(row[col]).strip().lower() == \"no value\" or row[col] == 0 for col in cols_to_check) >= 2\n",
    "    ),\n",
    "    axis=1\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows that still match the bad condition: 0\n"
     ]
    }
   ],
   "source": [
    "# to cehck\n",
    "# Redefine is_blank for use here too\n",
    "def is_blank(val):\n",
    "    return pd.isna(val) or str(val).strip() == \"\"\n",
    "\n",
    "# Check for rows that should have been dropped — sanity check\n",
    "bad_rows = df[df.apply(\n",
    "    lambda row: (\n",
    "        is_blank(row[\"Payment Method\"]) or is_blank(row[\"Location\"])\n",
    "    ) and (\n",
    "        sum(is_blank(row[col]) or str(row[col]).strip().lower() == \"no value\" or row[col] == 0 for col in cols_to_check) >= 2\n",
    "    ),\n",
    "    axis=1\n",
    ")]\n",
    "\n",
    "# Print how many got through (should be 0)\n",
    "print(\"Rows that still match the bad condition:\", len(bad_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"cafe_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
